{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70310e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d756463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Austin\\AppData\\Local\\Temp\\ipykernel_20928\\524115956.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(50, len(x)), random_state=42))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_name</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>suppicious play versus cpu cpu always win prov...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>want say something daily cash reward video wor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>get 40 pop ups play game good gam3 worth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>seem game rig look get 5 game win streak losin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>great gamegraphicsonly thing game fix lose mat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>game suck energy bar cannot play long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>please make character coustome character nice ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>perfect fight game whenever villian drop weapo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>game good controles super graphic also reason ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>game intreasting amaze learn newnew skill game</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_name                                            content  score\n",
       "0       8 Ball Pool  suppicious play versus cpu cpu always win prov...      2\n",
       "1       8 Ball Pool  want say something daily cash reward video wor...      3\n",
       "2       8 Ball Pool           get 40 pop ups play game good gam3 worth      1\n",
       "3       8 Ball Pool  seem game rig look get 5 game win streak losin...      2\n",
       "4       8 Ball Pool  great gamegraphicsonly thing game fix lose mat...      3\n",
       "..              ...                                                ...    ...\n",
       "995  Shadow Fight 2              game suck energy bar cannot play long      1\n",
       "996  Shadow Fight 2  please make character coustome character nice ...      5\n",
       "997  Shadow Fight 2  perfect fight game whenever villian drop weapo...      5\n",
       "998  Shadow Fight 2  game good controles super graphic also reason ...      3\n",
       "999  Shadow Fight 2     game intreasting amaze learn newnew skill game      5\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/GamesDataClean.csv\", usecols=[\"content\", \"score\", \"game_name\"])\n",
    "subset = (\n",
    "    data.groupby(\"game_name\", group_keys=False)\n",
    "        .apply(lambda x: x.sample(n=min(50, len(x)), random_state=42))\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "# subset = (\n",
    "#     data.groupby([\"game_name\", \"score\"], group_keys=False)\n",
    "#         .apply(lambda x: x.sample(n=min(200, len(x)), random_state=42))\n",
    "#         .reset_index(drop=True)\n",
    "# )\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc90038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "5    436\n",
       "1    248\n",
       "4    147\n",
       "3     91\n",
       "2     78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.value_counts('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326da5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subset[\"content\"].values\n",
    "y = subset[\"score\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516421d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4af33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TF-IDF =====\n",
      "Shape (train): (800, 7000)\n",
      "Jumlah kata unik/vocab: 7000\n",
      "Beberapa vocab: ['peak', 'twin', 'face', 'hold', 'back', 'tearsface', 'tear', 'peak twin', 'twin face', 'hold back', 'back tearsface', 'tearsface hold', 'play', 'roblox', 'year', 'single', 'problem', 'fun', 'multiple', 'platform']\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=7000, ngram_range=(1,2))  # unigram + bigram\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"\\n===== TF-IDF =====\")\n",
    "print(\"Shape (train):\", X_train_tfidf.shape)\n",
    "print(\"Jumlah kata unik/vocab:\", len(tfidf.vocabulary_))\n",
    "print(\"Beberapa vocab:\", list(tfidf.vocabulary_.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030025fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\envs\\TF\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + LR accuracy: 0.465\n",
      "\n",
      "Classification report (TF-IDF + LR):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6087    0.5600    0.5833        50\n",
      "           2     0.1250    0.1875    0.1500        16\n",
      "           3     0.1765    0.1667    0.1714        18\n",
      "           4     0.1892    0.2414    0.2121        29\n",
      "           5     0.6842    0.5977    0.6380        87\n",
      "\n",
      "    accuracy                         0.4650       200\n",
      "   macro avg     0.3567    0.3506    0.3510       200\n",
      "weighted avg     0.5031    0.4650    0.4816       200\n",
      "\n",
      "Confusion matrix:\n",
      " [[28  9  6  4  3]\n",
      " [ 4  3  3  3  3]\n",
      " [ 3  4  3  5  3]\n",
      " [ 4  2  1  7 15]\n",
      " [ 7  6  4 18 52]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        strip_accents=\"unicode\",\n",
    "        token_pattern=r\"[A-Za-z]{2,}\",   # words of 2+ letters\n",
    "        ngram_range=(1,2),               # uni+bi-grams usually best for sentiment\n",
    "        min_df=5,                        # ignore very rare terms\n",
    "        max_df=0.9,                      # ignore too-common terms\n",
    "        stop_words=\"english\",            # keep negations in text; vectorizer removes generic stopwords\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        multi_class=\"multinomial\",\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"lbfgs\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "tfidf_lr.fit(X_train, y_train)\n",
    "pred = tfidf_lr.predict(X_test)\n",
    "\n",
    "print(\"TF-IDF + LR accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"\\nClassification report (TF-IDF + LR):\\n\", classification_report(y_test, pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e571571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\envs\\TF\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(avg) + LR accuracy: 0.435\n",
      "\n",
      "Classification report (FastText + LR):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5455    0.4800    0.5106        50\n",
      "           2     0.1379    0.2500    0.1778        16\n",
      "           3     0.2308    0.3333    0.2727        18\n",
      "           4     0.1562    0.1724    0.1639        29\n",
      "           5     0.6957    0.5517    0.6154        87\n",
      "\n",
      "    accuracy                         0.4350       200\n",
      "   macro avg     0.3532    0.3575    0.3481       200\n",
      "weighted avg     0.4934    0.4350    0.4579       200\n",
      "\n",
      "Confusion matrix:\n",
      " [[24  9  5  6  6]\n",
      " [ 3  4  2  4  3]\n",
      " [ 2  6  6  3  1]\n",
      " [ 4  4  5  5 11]\n",
      " [11  6  8 14 48]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import FastText\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def tokenize_clean(s: str):\n",
    "    return s.split()\n",
    "\n",
    "sentences = [tokenize_clean(t) for t in subset[\"content\"]]\n",
    "y = subset[\"score\"].astype(int).values\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(sentences, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 3) Train FastText on the training sentences\n",
    "ft_dim = 300\n",
    "ft = FastText(\n",
    "    vector_size=ft_dim,\n",
    "    window=5,\n",
    "    min_count=5,          # raise/lower depending on corpus size\n",
    "    workers=os.cpu_count(),\n",
    "    sg=1,                 # skip-gram (semantic)\n",
    "    epochs=10\n",
    ")\n",
    "ft.build_vocab(corpus_iterable=X_train_s)\n",
    "ft.train(corpus_iterable=X_train_s, total_examples=len(X_train_s), epochs=ft.epochs)\n",
    "\n",
    "# 4) Sentence → vector (mean of word vectors)\n",
    "def sent_vec(tokens, model, dim):\n",
    "    if not tokens:\n",
    "        return np.zeros(dim, dtype=np.float32)\n",
    "    vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(dim, dtype=np.float32)\n",
    "\n",
    "Xtr = np.vstack([sent_vec(t, ft, ft_dim) for t in X_train_s])\n",
    "Xte = np.vstack([sent_vec(t, ft, ft_dim) for t in X_test_s])\n",
    "\n",
    "# 5) (Optional) scale embeddings; LR often benefits a bit\n",
    "scaler = StandardScaler()\n",
    "Xtr_s = scaler.fit_transform(Xtr)\n",
    "Xte_s = scaler.transform(Xte)\n",
    "\n",
    "# 6) Classifier\n",
    "clf_ft = LogisticRegression(\n",
    "    max_iter=2000, multi_class=\"multinomial\",\n",
    "    class_weight=\"balanced\", solver=\"lbfgs\", n_jobs=-1\n",
    ")\n",
    "clf_ft.fit(Xtr_s, y_train_s)\n",
    "pred_ft = clf_ft.predict(Xte_s)\n",
    "\n",
    "print(\"FastText(avg) + LR accuracy:\", round(accuracy_score(y_test_s, pred_ft), 4))\n",
    "print(\"\\nClassification report (FastText + LR):\\n\", classification_report(y_test_s, pred_ft, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_s, pred_ft))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
