{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70310e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d756463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Austin\\AppData\\Local\\Temp\\ipykernel_21576\\2573675864.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(50, len(x)), random_state=42))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_name</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>install game alot bug cheater game first game ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>lot fun great way pas time</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>discussting game pot ball way win jone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>think ball pool fun game play others plus get ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8 Ball Pool</td>\n",
       "      <td>great way focus something different thats fun ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>improve offline playingwhen return map finish ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>whenever watch ad get discount reduce time sti...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>wonderful animation nice game</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>shadow fight 2 amazing gamei use play year ago...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Shadow Fight 2</td>\n",
       "      <td>start less ad game go lot ad rest graphic weap...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_name                                            content  score\n",
       "0       8 Ball Pool  install game alot bug cheater game first game ...      1\n",
       "1       8 Ball Pool                         lot fun great way pas time      5\n",
       "2       8 Ball Pool             discussting game pot ball way win jone      1\n",
       "3       8 Ball Pool  think ball pool fun game play others plus get ...      5\n",
       "4       8 Ball Pool  great way focus something different thats fun ...      4\n",
       "..              ...                                                ...    ...\n",
       "995  Shadow Fight 2  improve offline playingwhen return map finish ...      5\n",
       "996  Shadow Fight 2  whenever watch ad get discount reduce time sti...      3\n",
       "997  Shadow Fight 2                      wonderful animation nice game      5\n",
       "998  Shadow Fight 2  shadow fight 2 amazing gamei use play year ago...      5\n",
       "999  Shadow Fight 2  start less ad game go lot ad rest graphic weap...      3\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"TopGamesDataClean.csv\", usecols=[\"content\", \"score\", \"game_name\"])\n",
    "subset = (\n",
    "    data.groupby(\"game_name\", group_keys=False)\n",
    "        .apply(lambda x: x.sample(n=min(50, len(x)), random_state=42))\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "# subset = (\n",
    "#     data.groupby([\"game_name\", \"score\"], group_keys=False)\n",
    "#         .apply(lambda x: x.sample(n=min(200, len(x)), random_state=42))\n",
    "#         .reset_index(drop=True)\n",
    "# )\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc90038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "5    457\n",
       "1    223\n",
       "4    136\n",
       "3    112\n",
       "2     72\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.value_counts('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326da5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subset[\"content\"].values\n",
    "y = subset[\"score\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516421d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4af33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TF-IDF =====\n",
      "Shape (train): (800, 7000)\n",
      "Jumlah kata unik/vocab: 7000\n",
      "Beberapa vocab: ['awsome', 'hard', 'get', 'server', 'even', 'try', 'join', 'say', 'full', 'really', 'need', 'fix', 'make', 'game', 'hack', 'annoy', 'hard get', 'even try', 'server say', 'server full']\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=7000, ngram_range=(1,2))  # unigram + bigram\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"\\n===== TF-IDF =====\")\n",
    "print(\"Shape (train):\", X_train_tfidf.shape)\n",
    "print(\"Jumlah kata unik/vocab:\", len(tfidf.vocabulary_))\n",
    "print(\"Beberapa vocab:\", list(tfidf.vocabulary_.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030025fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\envs\\TF\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + LR accuracy: 0.455\n",
      "\n",
      "Classification report (TF-IDF + LR):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1     0.4783    0.4889    0.4835        45\n",
      "           2     0.1429    0.2000    0.1667        15\n",
      "           3     0.1724    0.2273    0.1961        22\n",
      "           4     0.1515    0.1852    0.1667        27\n",
      "           5     0.7887    0.6154    0.6914        91\n",
      "\n",
      "    accuracy                         0.4550       200\n",
      "   macro avg     0.3468    0.3433    0.3409       200\n",
      "weighted avg     0.5166    0.4550    0.4799       200\n",
      "\n",
      "Confusion matrix:\n",
      " [[22  8  7  7  1]\n",
      " [ 7  3  1  3  1]\n",
      " [ 7  1  5  6  3]\n",
      " [ 4  2  6  5 10]\n",
      " [ 6  7 10 12 56]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        strip_accents=\"unicode\",\n",
    "        token_pattern=r\"[A-Za-z]{2,}\",   # words of 2+ letters\n",
    "        ngram_range=(1,2),               # uni+bi-grams usually best for sentiment\n",
    "        min_df=5,                        # ignore very rare terms\n",
    "        max_df=0.9,                      # ignore too-common terms\n",
    "        stop_words=\"english\",            # keep negations in text; vectorizer removes generic stopwords\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        multi_class=\"multinomial\",\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"lbfgs\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "tfidf_lr.fit(X_train, y_train)\n",
    "pred = tfidf_lr.predict(X_test)\n",
    "\n",
    "print(\"TF-IDF + LR accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"\\nClassification report (TF-IDF + LR):\\n\", classification_report(y_test, pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e571571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\envs\\TF\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(avg) + LR accuracy: 0.425\n",
      "\n",
      "Classification report (FastText + LR):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5676    0.4667    0.5122        45\n",
      "           2     0.0270    0.0667    0.0385        15\n",
      "           3     0.0741    0.0909    0.0816        22\n",
      "           4     0.2069    0.2222    0.2143        27\n",
      "           5     0.7857    0.6044    0.6832        91\n",
      "\n",
      "    accuracy                         0.4250       200\n",
      "   macro avg     0.3323    0.2902    0.3060       200\n",
      "weighted avg     0.5233    0.4250    0.4669       200\n",
      "\n",
      "Confusion matrix:\n",
      " [[21  9  6  4  5]\n",
      " [ 6  1  3  4  1]\n",
      " [ 7  6  2  5  2]\n",
      " [ 1 10  3  6  7]\n",
      " [ 2 11 13 10 55]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import FastText\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def tokenize_clean(s: str):\n",
    "    return s.split()\n",
    "\n",
    "sentences = [tokenize_clean(t) for t in subset[\"content\"]]\n",
    "y = subset[\"score\"].astype(int).values\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(sentences, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 3) Train FastText on the training sentences\n",
    "ft_dim = 300\n",
    "ft = FastText(\n",
    "    vector_size=ft_dim,\n",
    "    window=5,\n",
    "    min_count=5,          # raise/lower depending on corpus size\n",
    "    workers=os.cpu_count(),\n",
    "    sg=1,                 # skip-gram (semantic)\n",
    "    epochs=10\n",
    ")\n",
    "ft.build_vocab(corpus_iterable=X_train_s)\n",
    "ft.train(corpus_iterable=X_train_s, total_examples=len(X_train_s), epochs=ft.epochs)\n",
    "\n",
    "# 4) Sentence → vector (mean of word vectors)\n",
    "def sent_vec(tokens, model, dim):\n",
    "    if not tokens:\n",
    "        return np.zeros(dim, dtype=np.float32)\n",
    "    vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(dim, dtype=np.float32)\n",
    "\n",
    "Xtr = np.vstack([sent_vec(t, ft, ft_dim) for t in X_train_s])\n",
    "Xte = np.vstack([sent_vec(t, ft, ft_dim) for t in X_test_s])\n",
    "\n",
    "# 5) (Optional) scale embeddings; LR often benefits a bit\n",
    "scaler = StandardScaler()\n",
    "Xtr_s = scaler.fit_transform(Xtr)\n",
    "Xte_s = scaler.transform(Xte)\n",
    "\n",
    "# 6) Classifier\n",
    "clf_ft = LogisticRegression(\n",
    "    max_iter=2000, multi_class=\"multinomial\",\n",
    "    class_weight=\"balanced\", solver=\"lbfgs\", n_jobs=-1\n",
    ")\n",
    "clf_ft.fit(Xtr_s, y_train_s)\n",
    "pred_ft = clf_ft.predict(Xte_s)\n",
    "\n",
    "print(\"FastText(avg) + LR accuracy:\", round(accuracy_score(y_test_s, pred_ft), 4))\n",
    "print(\"\\nClassification report (FastText + LR):\\n\", classification_report(y_test_s, pred_ft, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_s, pred_ft))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
